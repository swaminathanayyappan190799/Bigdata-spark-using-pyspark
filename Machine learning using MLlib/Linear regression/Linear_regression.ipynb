{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Linear regression algorithm implementation using spark MLlib**\n",
    "\n",
    "Linear regression is one of the most familiar algorithm in machine learning, where we are trying to create a best fitting line for our datapoints that present on our dataset. The outcome of a linear regression model will be numerical (integer), so for any business use case which invloves in predicting the outcome of a integer based outcome linear regression model can be used for predicting it.\n",
    "\n",
    "Spark has an library known as \"MLlib\", which then allows us to implement several machine learning algorithms to our spark dataframe, it supports some of the supervised and unsupervised machine learning algorithms.\n",
    "\n",
    "> Creating a spark session\n",
    "\n",
    "> Data ingestion using spark\n",
    "\n",
    "> Exploring the data using spark functions\n",
    "\n",
    "> Segregating input and output features for the linear regression model\n",
    "\n",
    "> Using linear regression model from the spark MLlib library\n",
    "\n",
    "> Evaluating the model with regression evaluation metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating a spark session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a pyspark session\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession.builder.appName(\"linear_regression\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data ingestion using spark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "df=spark.read.csv(\"50_Startups.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploring data using pyspark functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- R&D Spend: double (nullable = true)\n",
      " |-- Administration: double (nullable = true)\n",
      " |-- Marketing Spend: double (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Printing schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(R&D Spend=165349.2, Administration=136897.8, Marketing Spend=471784.1, State='New York', Profit=192261.83),\n",
       " Row(R&D Spend=162597.7, Administration=151377.59, Marketing Spend=443898.53, State='California', Profit=191792.06),\n",
       " Row(R&D Spend=153441.51, Administration=101145.55, Marketing Spend=407934.54, State='Florida', Profit=191050.39),\n",
       " Row(R&D Spend=144372.41, Administration=118671.85, Marketing Spend=383199.62, State='New York', Profit=182901.99),\n",
       " Row(R&D Spend=142107.34, Administration=91391.77, Marketing Spend=366168.42, State='Florida', Profit=166187.94)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting first five rows of the dataframe.\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+----------+---------+\n",
      "|R&D Spend|Administration|Marketing Spend|     State|   Profit|\n",
      "+---------+--------------+---------------+----------+---------+\n",
      "| 165349.2|      136897.8|       471784.1|  New York|192261.83|\n",
      "| 162597.7|     151377.59|      443898.53|California|191792.06|\n",
      "|153441.51|     101145.55|      407934.54|   Florida|191050.39|\n",
      "|144372.41|     118671.85|      383199.62|  New York|182901.99|\n",
      "|142107.34|      91391.77|      366168.42|   Florida|166187.94|\n",
      "| 131876.9|      99814.71|      362861.36|  New York|156991.12|\n",
      "|134615.46|     147198.87|      127716.82|California|156122.51|\n",
      "|130298.13|     145530.06|      323876.68|   Florida| 155752.6|\n",
      "|120542.52|     148718.95|      311613.29|  New York|152211.77|\n",
      "|123334.88|     108679.17|      304981.62|California|149759.96|\n",
      "|101913.08|     110594.11|      229160.95|   Florida|146121.95|\n",
      "|100671.96|      91790.61|      249744.55|California| 144259.4|\n",
      "| 93863.75|     127320.38|      249839.44|   Florida|141585.52|\n",
      "| 91992.39|     135495.07|      252664.93|California|134307.35|\n",
      "|119943.24|     156547.42|      256512.92|   Florida|132602.65|\n",
      "|114523.61|     122616.84|      261776.23|  New York|129917.04|\n",
      "| 78013.11|     121597.55|      264346.06|California|126992.93|\n",
      "| 94657.16|     145077.58|      282574.31|  New York|125370.37|\n",
      "| 91749.16|     114175.79|      294919.57|   Florida| 124266.9|\n",
      "|  86419.7|     153514.11|            0.0|  New York|122776.86|\n",
      "+---------+--------------+---------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#viewing the spark dataframe\n",
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since state is a categorical feature, we might need to encode this strings into numbers where our AI model linear regression will accept only numeric inputs to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|     State|count|\n",
      "+----------+-----+\n",
      "|   Florida|   16|\n",
      "|California|   17|\n",
      "|  New York|   17|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For idetifying number of categories in the state column\n",
    "df.groupBy(\"State\").count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Converting state column to numeric form**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+----------+---------+-------------+\n",
      "|R&D Spend|Administration|Marketing Spend|     State|   Profit|Indexed_State|\n",
      "+---------+--------------+---------------+----------+---------+-------------+\n",
      "| 165349.2|      136897.8|       471784.1|  New York|192261.83|          1.0|\n",
      "| 162597.7|     151377.59|      443898.53|California|191792.06|          0.0|\n",
      "|153441.51|     101145.55|      407934.54|   Florida|191050.39|          2.0|\n",
      "|144372.41|     118671.85|      383199.62|  New York|182901.99|          1.0|\n",
      "|142107.34|      91391.77|      366168.42|   Florida|166187.94|          2.0|\n",
      "| 131876.9|      99814.71|      362861.36|  New York|156991.12|          1.0|\n",
      "|134615.46|     147198.87|      127716.82|California|156122.51|          0.0|\n",
      "|130298.13|     145530.06|      323876.68|   Florida| 155752.6|          2.0|\n",
      "|120542.52|     148718.95|      311613.29|  New York|152211.77|          1.0|\n",
      "|123334.88|     108679.17|      304981.62|California|149759.96|          0.0|\n",
      "|101913.08|     110594.11|      229160.95|   Florida|146121.95|          2.0|\n",
      "|100671.96|      91790.61|      249744.55|California| 144259.4|          0.0|\n",
      "| 93863.75|     127320.38|      249839.44|   Florida|141585.52|          2.0|\n",
      "| 91992.39|     135495.07|      252664.93|California|134307.35|          0.0|\n",
      "|119943.24|     156547.42|      256512.92|   Florida|132602.65|          2.0|\n",
      "|114523.61|     122616.84|      261776.23|  New York|129917.04|          1.0|\n",
      "| 78013.11|     121597.55|      264346.06|California|126992.93|          0.0|\n",
      "| 94657.16|     145077.58|      282574.31|  New York|125370.37|          1.0|\n",
      "| 91749.16|     114175.79|      294919.57|   Florida| 124266.9|          2.0|\n",
      "|  86419.7|     153514.11|            0.0|  New York|122776.86|          1.0|\n",
      "+---------+--------------+---------------+----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importing Stringindexer from pyspark for encoding state column\n",
    "#The output of this conversion will be saved in the Indexed column\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "Indexed = StringIndexer(inputCol=\"State\", outputCol=\"Indexed_State\")\n",
    "df=Indexed.fit(df).transform(df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R&D Spend',\n",
       " 'Administration',\n",
       " 'Marketing Spend',\n",
       " 'State',\n",
       " 'Profit',\n",
       " 'Indexed_State']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing the columns in the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+-------------+---------+\n",
      "|R&D Spend|Administration|Marketing Spend|Indexed_State|   Profit|\n",
      "+---------+--------------+---------------+-------------+---------+\n",
      "| 165349.2|      136897.8|       471784.1|          1.0|192261.83|\n",
      "| 162597.7|     151377.59|      443898.53|          0.0|191792.06|\n",
      "|153441.51|     101145.55|      407934.54|          2.0|191050.39|\n",
      "|144372.41|     118671.85|      383199.62|          1.0|182901.99|\n",
      "|142107.34|      91391.77|      366168.42|          2.0|166187.94|\n",
      "| 131876.9|      99814.71|      362861.36|          1.0|156991.12|\n",
      "|134615.46|     147198.87|      127716.82|          0.0|156122.51|\n",
      "|130298.13|     145530.06|      323876.68|          2.0| 155752.6|\n",
      "|120542.52|     148718.95|      311613.29|          1.0|152211.77|\n",
      "|123334.88|     108679.17|      304981.62|          0.0|149759.96|\n",
      "|101913.08|     110594.11|      229160.95|          2.0|146121.95|\n",
      "|100671.96|      91790.61|      249744.55|          0.0| 144259.4|\n",
      "| 93863.75|     127320.38|      249839.44|          2.0|141585.52|\n",
      "| 91992.39|     135495.07|      252664.93|          0.0|134307.35|\n",
      "|119943.24|     156547.42|      256512.92|          2.0|132602.65|\n",
      "|114523.61|     122616.84|      261776.23|          1.0|129917.04|\n",
      "| 78013.11|     121597.55|      264346.06|          0.0|126992.93|\n",
      "| 94657.16|     145077.58|      282574.31|          1.0|125370.37|\n",
      "| 91749.16|     114175.79|      294919.57|          2.0| 124266.9|\n",
      "|  86419.7|     153514.11|            0.0|          1.0|122776.86|\n",
      "+---------+--------------+---------------+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Selecting only the required columns from the dataframe.\n",
    "#Generally dropping the state column\n",
    "df=df.select(['R&D Spend','Administration','Marketing Spend','Indexed_State','Profit'])\n",
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Segregating input and output features for the linear regression model**\n",
    "\n",
    "Inorder to train a machine learning model, a dataframe should be splitted into two parts training and testing data and also we have to select the dependent(input columns), independent(output columns) from the dataframe to pass to the model.\n",
    "\n",
    "For doing this, pyspark has ml package which contains of the required packages and libraries for doing the machine learning related activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector assmbler package from pyspark will be useful in defining the input and output features to the model\n",
    "#And also it merge all the input features together into a column of vectors that has to be given as a input to the model.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vec_assembler = VectorAssembler(inputCols=['R&D Spend','Administration','Marketing Spend','Indexed_State'],outputCol=\"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the df using vector assembler.\n",
    "input_data = vec_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+-------------+---------+--------------------+\n",
      "|R&D Spend|Administration|Marketing Spend|Indexed_State|   Profit|            Features|\n",
      "+---------+--------------+---------------+-------------+---------+--------------------+\n",
      "| 165349.2|      136897.8|       471784.1|          1.0|192261.83|[165349.2,136897....|\n",
      "| 162597.7|     151377.59|      443898.53|          0.0|191792.06|[162597.7,151377....|\n",
      "|153441.51|     101145.55|      407934.54|          2.0|191050.39|[153441.51,101145...|\n",
      "|144372.41|     118671.85|      383199.62|          1.0|182901.99|[144372.41,118671...|\n",
      "|142107.34|      91391.77|      366168.42|          2.0|166187.94|[142107.34,91391....|\n",
      "| 131876.9|      99814.71|      362861.36|          1.0|156991.12|[131876.9,99814.7...|\n",
      "|134615.46|     147198.87|      127716.82|          0.0|156122.51|[134615.46,147198...|\n",
      "|130298.13|     145530.06|      323876.68|          2.0| 155752.6|[130298.13,145530...|\n",
      "|120542.52|     148718.95|      311613.29|          1.0|152211.77|[120542.52,148718...|\n",
      "|123334.88|     108679.17|      304981.62|          0.0|149759.96|[123334.88,108679...|\n",
      "|101913.08|     110594.11|      229160.95|          2.0|146121.95|[101913.08,110594...|\n",
      "|100671.96|      91790.61|      249744.55|          0.0| 144259.4|[100671.96,91790....|\n",
      "| 93863.75|     127320.38|      249839.44|          2.0|141585.52|[93863.75,127320....|\n",
      "| 91992.39|     135495.07|      252664.93|          0.0|134307.35|[91992.39,135495....|\n",
      "|119943.24|     156547.42|      256512.92|          2.0|132602.65|[119943.24,156547...|\n",
      "|114523.61|     122616.84|      261776.23|          1.0|129917.04|[114523.61,122616...|\n",
      "| 78013.11|     121597.55|      264346.06|          0.0|126992.93|[78013.11,121597....|\n",
      "| 94657.16|     145077.58|      282574.31|          1.0|125370.37|[94657.16,145077....|\n",
      "| 91749.16|     114175.79|      294919.57|          2.0| 124266.9|[91749.16,114175....|\n",
      "|  86419.7|     153514.11|            0.0|          1.0|122776.86|[86419.7,153514.1...|\n",
      "+---------+--------------+---------------+-------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Listing the df after the conversion\n",
    "#The features column will be the input and it's the last column of the dataframe.\n",
    "input_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only the features and profit column from the dataframe.\n",
    "input_data = input_data.select([\"Features\",\"Profit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            Features|   Profit|\n",
      "+--------------------+---------+\n",
      "|[165349.2,136897....|192261.83|\n",
      "|[162597.7,151377....|191792.06|\n",
      "|[153441.51,101145...|191050.39|\n",
      "|[144372.41,118671...|182901.99|\n",
      "|[142107.34,91391....|166187.94|\n",
      "|[131876.9,99814.7...|156991.12|\n",
      "|[134615.46,147198...|156122.51|\n",
      "|[130298.13,145530...| 155752.6|\n",
      "|[120542.52,148718...|152211.77|\n",
      "|[123334.88,108679...|149759.96|\n",
      "|[101913.08,110594...|146121.95|\n",
      "|[100671.96,91790....| 144259.4|\n",
      "|[93863.75,127320....|141585.52|\n",
      "|[91992.39,135495....|134307.35|\n",
      "|[119943.24,156547...|132602.65|\n",
      "|[114523.61,122616...|129917.04|\n",
      "|[78013.11,121597....|126992.93|\n",
      "|[94657.16,145077....|125370.37|\n",
      "|[91749.16,114175....| 124266.9|\n",
      "|[86419.7,153514.1...|122776.86|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Viewing the final datframe\n",
    "input_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataframe into training and testing data.\n",
    "#Training data will be used to train the model, similarly testing data will be used to test the trained model.\n",
    "train_data, test_data = input_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using linear regression model from the spark MLlib library**\n",
    "\n",
    "Linear regression is a mathematical algorith , which is also known as least squared method which invloves in predicting an quantitative (numerical) based outcome depends on the input features. In other works linear regression tends to find the best fitting line to ,cover almost all the datapoints of the input feature such that if any new input feature comes in it will be predicted based on the best fitting line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing linear regression module from pyspark ml module.\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol=\"Features\", labelCol=\"Profit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the linear regression model with the training data.\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.875, -0.0894, 0.0191, 151.7491])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtaining the co-efficients of the trained linear regression model.\n",
    "lr_model.coefficients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation of the trained linear regression model using regression evaluation metrics**\n",
    "\n",
    "There are certain metrics which are available to evaluate a trained regression model, those are\n",
    "1) Mean absolute error\n",
    "2) Mean squared error\n",
    "3) Root mean squared error\n",
    "3) R squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model performance using testing data.\n",
    "results = lr_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE)  : 9173.393807110879\n",
      "Mean Squared Error (MSE)  :  126037249.99652538\n",
      "Root Mean Squared Error (RMSE) : 11226.631284429242\n",
      "R Squared error : 0.8828224793862188\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Absolute Error (MAE)  : {results.meanAbsoluteError}\")\n",
    "print(f\"Mean Squared Error (MSE)  :  {results.meanSquaredError}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) : {results.rootMeanSquaredError}\")\n",
    "print(f\"R Squared error : {results.r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
